\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{algorithm2e}
\usepackage{color}

%\renewcommand{\baselinestretch}{0.96}
%\renewcommand{\floatsep}{6pt}
%\renewcommand{\dblfloatsep}{3pt}
%\renewcommand{\textfloatsep}{6pt}
%\renewcommand{\dbltextfloatsep}{6pt}
%\addtolength{\topsep}{-3pt}
%\addtolength{\partopsep}{-3pt}
%\addtolength{\itemsep}{-3pt}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks\thanks{This work is conducted during Chunshui Cao's and Xianming Liu's internship at Institute of Deep Learning, Baidu Research }}


\author{Chunshui Cao$^\dag$ \;\; Xianming Liu$^\ddag$ \;\; Yi Yang$^\S$ \;\; \\
Yinan Yu$^\natural$ \;\; Zilei Wang$^\dag$ \;\; Yongzhen Huang$^*$ \;\; Liang Wang $^*$ \;\; \\
Deva Ramanan$^\sharp$ \;\; Thomas S. Huang$^\ddag$ \\
$^\dag$Department of Automation, University of Science and Technology of China\\
$^\ddag$Beckman Institute, University of Illinois at Urbana-Champaign\\
$^\S$Baidu Research \quad $^\natural$Horizontal Robotics\\
$^*$CEBSIT center, Institute of Automation, Chinese Academy of Sciences\\
$^\sharp$Carnegie Mellon University \\
{\tt \small \{ccs, zileiwang\}@ia.ac.cn \;\; \{xliu102,t-huang1\}@illinois.edu \;\; yangyi05@baidu.com \;\;}\\
{\tt \small yuyinan@baidu.com \;\; deva@cs.cmu.edu \;\; \{yzhuang, wangliang\}@nlpr.ia.ac.cn\;\;}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
While feedforward deep convolutional neural networks (CNNs) have been a great success in computer vision, it is important to note that the human visual cortex generally contains more feedback than feedforward connections.
In this paper, we will briefly introduce the background of feedbacks in the human visual cortex, which motivates us to develop a computational feedback mechanism in deep neural networks.
In addition to the feedforward inference in traditional neural networks, a feedback loop is introduced to infer the activation status of hidden layer neurons according to the ``goal'' of the network, e.g., high-level semantic labels.
We analogize this mechanism as ``\textbf{Look and Think Twice}.''
The feedback networks help better visualize and understand how deep neural networks work, and capture visual attention on expected objects, even in images with cluttered background and multiple objects.
Experiments on ImageNet dataset demonstrate its effectiveness in solving tasks such as image classification and object localization.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{camera-ready_secs/intro}
\input{camera-ready_secs/related_work}
\input{camera-ready_secs/model}
\input{camera-ready_secs/experiment}
\input{camera-ready_secs/conclusion}

% This is newly added. I just add acknowledge of NVIDIA donation program here. Feel free to add grant unless it is not exceeding the 9 page limitation
\section*{Acknowledgement}
We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPUs used in the prototyping stage of this research.
This research is supported by National Science Foundation under Grant No. 1318971.

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
