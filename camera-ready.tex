\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{algorithm2e}
\usepackage{color}

%\renewcommand{\baselinestretch}{0.96}
\renewcommand{\floatsep}{6pt}
\renewcommand{\dblfloatsep}{3pt}
\renewcommand{\textfloatsep}{6pt}
\renewcommand{\dbltextfloatsep}{6pt}
\addtolength{\topsep}{-3pt}
\addtolength{\partopsep}{-3pt}
\addtolength{\itemsep}{-3pt}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks}

\author{Chunshui Cao, Tieniu Tan\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Xianming Liu, Thomas Huang\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
\and
Yi Yang\\
Baidu Research\\
First line of institution2 address\\
{\tt\small yangyi05@baidu.com}
\and
Yinan Yu\\
Horizontal Robotics\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
\and
Deva Ramanan\\
Carnegie Mellon University\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
While feedforward deep convolutional neural networks (CNNs) have been a great success in computer vision, it is important to note that the human visual context generally contains more feedback than feedforward connections.
In this paper, we will briefly introduce the background of feedbacks in the human visual cortex, which motivates us to develop a computational feedback mechanism in deep neural networks.
The proposed networks perform inference from images in a bottom-up manner as traditional convolutional networks; while during feedback loops it sets up high-level semantic labels as the “goal” to infer the activation status of hidden layer neurons.
The feedback networks help us better visualize and understand how deep neural networks work as well as capture visual attention on expected objects, even in images with cluttered background and multiple objects.
Experiments on ImageNet dataset demonstrate its effectiveness in improving traditional computer vision tasks such as classification and object localization.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{camera-ready_secs/intro}
\input{camera-ready_secs/related_work}
\input{camera-ready_secs/model}
\input{camera-ready_secs/experiment}
\input{camera-ready_secs/conclusion}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
