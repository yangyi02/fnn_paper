\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{algorithm2e}
\usepackage{color}

%\renewcommand{\baselinestretch}{0.96}
\renewcommand{\floatsep}{6pt}
\renewcommand{\dblfloatsep}{3pt}
\renewcommand{\textfloatsep}{6pt}
\renewcommand{\dbltextfloatsep}{6pt}
\addtolength{\topsep}{-3pt}
\addtolength{\partopsep}{-3pt}
\addtolength{\itemsep}{-3pt}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks\thanks{This work is conducted during Chunshui Cao's and Xianming Liu's internship at Institute of Deep Learning, Baidu Research }}


\author{Chunshui Cao$^\dag$ \;\; Xianming Liu$^\ddag$ \;\; Yi Yang$^\S$ \;\; Yinan Yu$^\natural$ \;\; \\
Deva Ramanan$^\sharp$ \;\; Tieniu Tan$^\dag$ \;\; Thomas S. Huang$^\ddag$ \\
$^\dag$Institute of Automation, Chinese Academy of Science\\
$^\ddag$Beckman Institute, University of Illinois at Urbana-Champaign\\
$^\S$Baidu Research \quad $^\natural$Horizontal Robotics\\
$^\sharp$Carnegie Mellon University \\
{\tt \small \{***\}@ia.ac.cn \;\; \{xliu102,t-huang1\}@illinois.edu \;\; yangyi05@baidu.com \;\;}\\
{\tt \small ***@***.com \;\; deva@cs.cmu.edu }
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
While feedforward deep convolutional neural networks (CNNs) have been a great success in computer vision, it is important to note that the human visual context generally contains more feedback than feedforward connections.
In this paper, we will briefly introduce the background of feedbacks in the human visual cortex, which motivates us to develop a computational feedback mechanism in deep neural networks.
In addition to the feedforward inference in traditional neural networks, a feedback loop is introduced to infer the activation status of hidden layer neurons according to the ``goal'' of the network, e.g., high-level semantic labels.
We analogize this mechanism as ``\textbf{Look and Think Twice}.''
The feedback networks help better visualize and understand how deep neural networks work, and capture visual attention on expected objects, even in images with cluttered background and multiple objects.
Experiments on ImageNet dataset demonstrate its effectiveness in solving tasks such as classification and object localization.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{camera-ready_secs/intro}
\input{camera-ready_secs/related_work}
\input{camera-ready_secs/model}
\input{camera-ready_secs/experiment}
\input{camera-ready_secs/conclusion}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
