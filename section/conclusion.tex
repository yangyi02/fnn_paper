\section{Conclusion \& Discussion}
\label{sec:conclusion}

We propose a Feedback Convolutional Neural Network architecture in this paper, which achieves the selectivity of neuron activations by jointly reasoning the outputs of class nodes and the activations of hidden layer neurons during the feedback loop. The proposed Feedback CNN is capable of capturing high level semantic concepts and project the information down to image representation as salience maps. Benefiting from the feedback mechanism of our model, we utilize the salience map to build a unified deep neural network for both recognition and object localization tasks, to answer questions of both ``What'' and ``Where'' simultaneously. Experimental results on ImageNet 2014 object localization Challenge show that our model could achieve competitive performance compared with state-of-the-arts, using only weakly supervised information.

%The Feedback CNNs have the potential to further improve various computer vision and machine learning tasks, such as fine-grained recognition, multi-task learning, and object detection. While they may also help training better CNN models with semi-supervised learning. We leave these topics as future work. 

% Finally, I wrote down this sentence and comment it. It will make sense, but may not be suitable to put it here.
% In the meanwhile, we are also wondering how human perception and cognitive mechanism would help in computer vision and machine learning. Instead of simulating the human vision system, building an efficient computational model that works for computer is more promising.

\begin{comment}
We proposes a Feedback Convolusional Neural Networks for class model visualization and object localization.
Our Feedback Neural Networks can infer the hidden neuron status given the bottom level input image and top level class labels.
Experiments on ImageNet localization challengeindicates that our model is superior in weakly supervised object localization, and further experiments demonstrate its powerfulness in distinguishing objects, even under cluttered backgrounds with multiple objects.

(1) Robust
(2) Multi-task
(3)

Figure 1: We show the powerfulness of feedback neural networks on class model visualization and object localizations, even when an image contains very cluttered background and lots of salient objects. Note that we simply use a pertained feedforward multi-class convnets (GoogleNet) model [] trained with ImageNet dataset where each training image only contains one object and no further training is involved. The feedback neural nets are able to adapt its middle-level hidden layers (usually represents object parts) by combining the bottom-up feedforward image features as well as top-down feedback semantic information. (a) input image (b) class model visualization given the class label: panda, elephant, gorilla, tiger, lion, (c) final object localization results based on the class model visualization.
\end{comment}
