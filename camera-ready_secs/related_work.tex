\section{Related Work}
\label{sec:related_work}

% Organization: 1) feedforward cnn 2) feedback network: RBM, Deconvolution, RNN. 3) visualization and attention 4) localization and detection
\subsection{Feedforward and Feedback Mechanism}
Deep Neural Network takes a \emph{feedforward-Back Error Propagation} strategy to learn features and classifiers simultaneously, from large scale of training samples~\cite{Krizhevsky2012ImageNet,Simonyan2014Very,lin2013network,salakhutdinov2009deep,bengio2013representation}. Various approaches have been proposed to further improve the discriminative ability of deep neural network, either by 1) adding regularization to improve the robustness of learnt model and get rid of overfitting, such as Dropout~\cite{srivastava2014dropout}, PReLU~\cite{he2015delving}, Batch Normalization~\cite{ioffe2015batch}; or 2) making the network deeper~\cite{Szegedy2014Going,Simonyan2014Very}.

Despite great successes achieved by applying Feedforward Networks to image recognition and detection, evidences accumulate from cognitive studies and point to the feedback mechanism that may dominant human perception processes~\cite{Cichy2014Resolving,Rust:2010if,Kruger2013Deep,lee2003hierarchical}. Recently, tentative efforts have been made to involve feedback strategy into Deep Neural Networks. Deep Boltzmman Machines (DBM)~\cite{salakhutdinov2009deep,sohn2013learning} and Deconvolutional Nerual Networks~\cite{Zeiler:2011hy} try to formulate the feedback as a reconstruction process within the training stage. Meanwhile, Recurrent Neural Networks (RNN) and Long Short Term Memory (LSTM)~\cite{hochreiter1997long} are utilized to capture the attention drifting in a dynamic environment and learn the feedback mechanisms via reinforcement learning~\cite{Stollenga:2014tl,Mnih:2014ti}. DRAW from Google DeepMind~\cite{gregor2015draw} combine above two into a generative model, to synthesis the image generation process.

As in \emph{Biased Competition Theory}~\cite{beck2009top,desimone1995neural}, feedback, which passes the high-level semantic information down to the low-level perception, controls the selectivity of neuron activations in an extra loop in addition to the feedforward process. This results in the ``Top-Down'' attention in human cognition. Hierarchical probabilistic computational models~\cite{lee2003hierarchical} are proposed to characterize feedback stimuli in a top-down manner, which are further incorporated into deep neural networks, for example, modeling feedback as latent variables in DBM~\cite{wang2014attentional}, or using selectivity to resolve fine-grained classification~\cite{Mnih:2014ti}, \emph{et al.}. However, generative models used in~\cite{Mnih:2014ti,wang2014attentional} are limited by low computational efficiency and capacity, and are hardly used in large scale datasets.

\subsection{Visualization, Detection, and Localization}

Feedback is often related with visualization of CNN and object localization since both of them aim to project the high-level semantic information back to image representations. To visualize neuron responses and class models, various approaches are proposed either using deconvolution~\cite{zeiler2014visualizing} or optimization based on gradients~\cite{simonyan2013deep, le2013building}. As demonstrated in \cite{simonyan2013deep}, visualization of Convolutional Neural Network shows semantically meaningful salient object regions and helps understand working mechanism of CNNs.

Object detection and localization are more about feedback, by treating detection / localization as a searching process with clear ``goals.'' To localize and detect objects in images, typical approaches use supervised training, which relies on large amount of supervision, \emph{e.g.}, ground-truth bounding boxes, or manually labeled segmentation in training samples~\cite{erhan2014scalable}. To behave ``searching'', sliding window is used~\cite{erhan2014scalable}, or instead region proposals detected by image segmentations~\cite{uijlings2013selective} in R-CNN~\cite{girshick2014rich}. However, both of these approaches are computational intensive and naturally bottom-up: selecting candidate regions, performing feedforward classification and making decisions.

Inspired by visualizations of CNNs~\cite{zeiler2014visualizing,simonyan2013deep}, a more feasible and cognitive manner for detection / localization could be derived by utilizing the saliency maps generated in feedback visualizations. Moreover, an ideal approach should unify the recognition and detection in a single feedforward-feedback network architecture. However, if possible, the challenge lies on how to obtain semantically meaningful salience maps with high quality for each concept. That's the ultimate goal of our work presented in this paper.
